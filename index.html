<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8">
		<title>MLiature</title>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i,900,900i">
        <link rel="stylesheet" href="reset.css">
		<link rel="stylesheet" href="article.css">
		<link rel="stylesheet" href="article-figure.css">
		<link rel="stylesheet" href="article-text.css">
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
 <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>

	</head>
    <body>
		<article id="header-1">
			<h1><a>This site showcases The <em>AI Capstone Project</em></a></h1>
			<h2>Session 2024-25</h2>

			<time datetime="12-07-2024">JULY. 12, 2024</time>
			<p>
				By Tejas,Akshay,Shreya,Satvik,Sparsh and Prince.<br>
				Class  12 C2
			</p>
			
			<figure id="container" style=" 
	display: flex;
">
				 <canvas id="canvas" width="640" height="480" ></canvas>
                    <video id="video" muted="muted" playsinline="" style="transform:scaleX(-1);visibility:hidden;width:0;height:0"></video>

			</figure>
			<figcaption><p>Pose Estimation</p></figcaption>

			<h3>About the project</h3>
			<p>
				MLiature is a portmanteau of Machine Learning(ML) and Miniature paintings(-iature).
				The project symbolizes the rich cultural heritage of India
				in the aspect of art.<br>
				It is backed by a realtime pose estimation model trained by google,MoveNet Lightning.
			</p>
			<footer>
			  <p><a href="logbook.docx">See the project logbook</a></p>
			  <p>Team Email: <a href="mailto:mliatureaiprojecttps@gmail.com">mliatureaiprojecttps@gmail.com</a></p>
			</footer>
		</article>
    </body>


		<script>
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
let frame = 0;
const ctx = canvas.getContext('2d');
if ('mediaDevices' in navigator && 'getUserMedia' in navigator.mediaDevices) {
  console.log("mediaDevices found in navigator.getUserMedia found in mediaDevices")
}

// Create scene, camera, and renderer
const scene = new THREE.Scene();
const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
const renderer = new THREE.WebGLRenderer();
renderer.setSize(canvas.width,canvas.height);
document.getElementById("container").appendChild(renderer.domElement);
// Create a plane
const planeGeometry = new THREE.PlaneGeometry(10, 10);
const planeMaterial = new THREE.MeshBasicMaterial({ color: 0xAAAAAA, side: THREE.DoubleSide });
const plane = new THREE.Mesh(planeGeometry, planeMaterial);
plane.rotation.x = Math.PI / 2;
scene.add(plane);

// Create a cube
const geometry = new THREE.BoxGeometry();
const material = new THREE.MeshBasicMaterial({ color: 0x00ff00 });
const cube = new THREE.Mesh(geometry, material);
scene.add(cube);

// Set initial camera position
camera.position.z = 5;
camera.position.y = 5;
camera.lookAt(0, 0, 0);

// Movement and rotation variables
let moveSpeed = 0.1;
let rotateSpeed = 0.02;
let running = false;
const detectorConfig = {modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING};
let detector;

async function cameraToVideo (){
const stream = await navigator.mediaDevices.getUserMedia({video: true});
video.srcObject = stream;
}

async function videoToCanvas(){

if( frame%5==0){
 poses = await detector.estimatePoses(video);
}

if (frame<60){
frame +=1;
}else{
frame=0;
}

   ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.scale(-1, 1);
    ctx.translate(-canvas.width, 0);
    ctx.drawImage(video, 0, 0);
for(let i=5;i<16;i++){
if (poses[0]){
//ctx.globalAlpha = 0.5;
ctx.fillStyle = "rgb(255,255,255)";
ctx.beginPath();
ctx.arc(poses[0]['keypoints'][i]['x'],poses[0]['keypoints'][i]['y'],8,0,2*Math.PI);
ctx.fill();
console.log(poses[0].keypoints);
drawLine("left_shoulder","right_shoulder");
drawLine("left_shoulder","left_hip");
drawLine("right_shoulder","right_hip");
drawLine("right_hip","right_hip");
drawLine("left_shoulder","left_elbow");
drawLine("left_elbow","left_wrist");
drawLine("right_shoulder","right_elbow");
drawLine("right_elbow","right_wrist");

drawLine("left_hip","left_knee");
drawLine("left_knee","left_ankle");
drawLine("right_hip","right_knee");
drawLine("right_knee","right_ankle");
drawLine("left_hip","right_hip");
ctx.stroke();
}
}

    ctx.setTransform(1, 0, 0, 1, 0, 0);
//renderer.render(scene, camera);
requestAnimationFrame(videoToCanvas);
}
async function initialise(){
detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, detectorConfig);
requestAnimationFrame(videoToCanvas);
}
function drawLine(a_p1,a_p2){
let p1 =  getPoint(a_p1);
let p2 = getPoint(a_p2);
if( p1 && p2){
ctx.lineWidth = 4;
ctx.strokeStyle = "rgb(255,255,255)";
ctx.moveTo(p1.x,p1.y);
ctx.lineTo(p2.x,p2.y);
//ctx.stroke();
}

}
function getPoint(k){
let n = poses[0].keypoints.find(point=>point.name===k);
return n;
}
/*
function game(){

// Event listener for keyboard input to control cube movement and rotation
document.addEventListener('keydown', (event) => {
    switch (event.code) {
        case 'ArrowUp':
            cube.position.z -= moveSpeed;
            break;
        case 'ArrowDown':
            cube.position.z += moveSpeed;
            break;
        case 'ArrowLeft':
            cube.position.x -= moveSpeed;
            break;
        case 'ArrowRight':
            cube.position.x += moveSpeed;
            break;
        case 'KeyW':
            cube.rotation.x -= rotateSpeed;
            break;
        case 'KeyS':
            cube.rotation.x += rotateSpeed;
            break;
        case 'KeyA':
            cube.rotation.y -= rotateSpeed;
            break;
        case 'KeyD':
            cube.rotation.y += rotateSpeed;
            break;
    }
});


}*/
video.play()
cameraToVideo();
initialise();
</script>

</html>
