<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8">
		<title>MLiature</title>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i,900,900i">
        <link rel="stylesheet" href="reset.css">
		<link rel="stylesheet" href="article.css">
		<link rel="stylesheet" href="article-figure.css">
		<link rel="stylesheet" href="article-text.css">
		<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
 <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r134/three.min.js"></script>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>

	</head>
    <body>
		<article id="header-1">
			<h1><a>This site showcases The <em>AI Capstone Project</em></a></h1>
			<h2>Session 2024-25</h2>

			<time datetime="12-07-2024">JULY. 12, 2024</time>
			<p>
				By Tejas,Akshay,Shreya,Satvik,Sparsh and Prince.<br>
				Class  12 C2
			</p>
			
			<figure id="container" style=" 
	display: flex;
">
				 <canvas id="canvas" width="640" height="480" ></canvas>
                    <video id="video" muted="muted" playsinline="" style="transform:scaleX(-1);visibility:hidden;width:0;height:0"></video>

			</figure>
			<figcaption><p>Pose Estimation</p></figcaption>

			<h3>About the project</h3>
			<p>
				MLiature is a portmanteau of Machine Learning(ML) and Miniature paintings(-iature).
				The project symbolizes the rich cultural heritage of India
				in the aspect of art.<br>
				It is backed by a realtime pose estimation model trained by google,MoveNet Lightning.
			</p>
			<footer>
			  <p><a href="logbook.docx">See the project logbook</a></p>
			  <p>Team Email: <a href="mailto:mliatureaiprojecttps@gmail.com">mliatureaiprojecttps@gmail.com</a></p>
			</footer>
		</article>
    </body>


		<script>
//TODO--Increase confidence threshold
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
let frame = 0;
const ctx = canvas.getContext('2d');
if ('mediaDevices' in navigator && 'getUserMedia' in navigator.mediaDevices) {
  console.log("mediaDevices found in navigator.getUserMedia found in mediaDevices")
}

const detectorConfig = {modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING};
let detector;

async function cameraToVideo (){
const stream = await navigator.mediaDevices.getUserMedia({video: true});
video.srcObject = stream;
}

async function videoToCanvas(){

if( frame%3==0){
 poses = await detector.estimatePoses(video,{flipHorizontal:true});
}

if (frame<60){
frame +=1;
}else{
frame=0;
}

   ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.scale(-1, 1);
    ctx.translate(-canvas.width, 0);
ctx.globalAlpha = 1.0;

    ctx.drawImage(video, 0, 0);
if (poses[0]){
for(let i=5;i<16;i++){
ctx.globalAlpha = 0.5;
ctx.fillStyle = "rgb(255,255,255)";
ctx.beginPath();
ctx.arc(poses[0]['keypoints'][i]['x'],poses[0]['keypoints'][i]['y'],8,0,2*Math.PI);
ctx.fill();
console.log(poses[0].keypoints);
}
ctx.strokeStyle = "rgb(255,255,255)";
drawLine("left_shoulder","right_shoulder");
drawLine("left_shoulder","left_hip");
ctx.strokeStyle = "rgb(255,255,255)";
drawLine("right_shoulder","right_hip");
drawLine("right_hip","right_hip");
drawLine("left_shoulder","left_elbow");
drawLine("left_elbow","left_wrist");
drawLine("right_shoulder","right_elbow");
drawLine("right_elbow","right_wrist");

drawLine("left_hip","left_knee");
drawLine("left_knee","left_ankle");
drawLine("right_hip","right_knee");
drawLine("right_knee","right_ankle");
drawLine("left_hip","right_hip");
ctx.stroke();
}
ctx.setTransform(1, 0, 0, 1, 0, 0);
requestAnimationFrame(videoToCanvas);
}
async function initialise(){
detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, detectorConfig);
requestAnimationFrame(videoToCanvas);
}
function drawLine(a_p1,a_p2){
let p1 =  getPoint(a_p1);
let p2 = getPoint(a_p2);
if( p1 && p2){
ctx.lineWidth = 4;
ctx.moveTo(p1.x,p1.y);
ctx.lineTo(p2.x,p2.y);
}

}
function getPoint(k){
let n = poses[0].keypoints.find(point=>point.name===k);
return n;
}
video.play()
cameraToVideo();
initialise();
</script>

</html>
